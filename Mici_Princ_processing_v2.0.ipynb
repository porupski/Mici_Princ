{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11c2f0b-a5ee-4424-91f4-c3b06dc5d56e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:55:05.096084Z",
     "iopub.status.busy": "2024-08-05T16:55:05.095088Z",
     "iopub.status.idle": "2024-08-05T16:55:05.100890Z",
     "shell.execute_reply": "2024-08-05T16:55:05.100890Z",
     "shell.execute_reply.started": "2024-08-05T16:55:05.096084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the base directory paths\n",
    "audio_base_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\MP.mp3\"\n",
    "transcript_dir_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\MP.json\"  # Directory containing MP_00.json to MP_28.json\n",
    "output_file_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\all_mp3s.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12265e2b-64f6-4f2c-a884-a47780a0e303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:55:05.267444Z",
     "iopub.status.busy": "2024-08-05T16:55:05.267444Z",
     "iopub.status.idle": "2024-08-05T16:55:05.279040Z",
     "shell.execute_reply": "2024-08-05T16:55:05.279040Z",
     "shell.execute_reply.started": "2024-08-05T16:55:05.267444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP3 file data extracted and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the base directory paths\n",
    "audio_base_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\MP.mp3\"\n",
    "output_file_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\all_mp3_files.json\"\n",
    "\n",
    "def extract_mp3_files(base_directory):\n",
    "    mp3_files_dict = {}\n",
    "    for filename in os.listdir(base_directory):\n",
    "        if filename.endswith('.mp3'):\n",
    "            match = re.match(r'(MP_\\d{2})_(\\d+\\.\\d+)-(\\d+\\.\\d+)\\.mp3', filename)\n",
    "            if match:\n",
    "                base_name = match.group(1)\n",
    "                start_time = float(match.group(2))\n",
    "                end_time = float(match.group(3))\n",
    "                \n",
    "                # Initialize the list for the base name if not present\n",
    "                if base_name not in mp3_files_dict:\n",
    "                    mp3_files_dict[base_name] = []\n",
    "                \n",
    "                # Append the file details to the respective base name\n",
    "                mp3_files_dict[base_name].append({\n",
    "                    \"filename\": filename,\n",
    "                    \"start_time\": start_time,\n",
    "                    \"end_time\": end_time\n",
    "                })\n",
    "    \n",
    "    # Sort each list of files by start time\n",
    "    for base_name in mp3_files_dict:\n",
    "        mp3_files_dict[base_name].sort(key=lambda x: x[\"start_time\"])\n",
    "    \n",
    "    return mp3_files_dict\n",
    "\n",
    "def main():\n",
    "    # Extract MP3 files and their details\n",
    "    all_mp3_files = extract_mp3_files(audio_base_path)\n",
    "    \n",
    "    # Save the data into a JSON file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(all_mp3_files, outfile, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print('MP3 file data extracted and saved successfully!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3394e6-bd19-4aa7-99ea-f527410bd4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:11:15.566467Z",
     "iopub.status.busy": "2024-08-05T17:11:15.566467Z",
     "iopub.status.idle": "2024-08-05T17:11:15.739644Z",
     "shell.execute_reply": "2024-08-05T17:11:15.739644Z",
     "shell.execute_reply.started": "2024-08-05T17:11:15.566467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated transcript data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the base directory paths\n",
    "transcript_dir_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\MP.json\"  # Directory containing MP_00.json to MP_28.json\n",
    "mp3_files_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\all_mp3_files.json\"\n",
    "output_file_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\consolidated_transcript.json\"\n",
    "\n",
    "# Define tolerance for floating-point comparisons\n",
    "FLOAT_TOLERANCE = 0.01  # Adjust this tolerance as needed\n",
    "\n",
    "def load_mp3_files(mp3_files_path):\n",
    "    with open(mp3_files_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_transcript(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Record positions of newlines\n",
    "    newline_positions = [m.start() for m in re.finditer(r'\\n', text)]\n",
    "\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Continue with existing preprocessing steps\n",
    "    text = re.sub(r'\\•\\s+', '•_', text)  # Combine \"• \" with following word\n",
    "    text = re.sub(r'\\-\\s+', '-_', text)  # Combine \"- \" with following word\n",
    "    text = re.sub(r'(\\S) – (\\S)', r'\\1– \\2', text)  # Handle long hyphens\n",
    "    text = re.sub(r'(\\S)-(\\S)', r'\\1- \\2', text)  # Split hyphenated words\n",
    "    text = re.sub(r'(\\S)\\s*\\.\\.\\.', r'\\1...', text)  # Append ellipses\n",
    "    text = re.sub(r'„\\s+(\\w)', r'„\\1', text)\n",
    "    text = re.sub(r'„\\s+(\\w)', r'„\\1', text)\n",
    "\n",
    "    return text, newline_positions\n",
    "\n",
    "    \n",
    "def sync_words_to_mp3(mp3_files, transcript):\n",
    "    for mp3 in mp3_files:\n",
    "        mp3['words'] = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        speaker = entry['speaker']\n",
    "        text, newline_positions = preprocess_text(entry['text'])\n",
    "        words = text.split(' ')\n",
    "        timing_words = entry['words']\n",
    "\n",
    "        # Debugging output\n",
    "        if len(words) != len(timing_words):\n",
    "            print(f\"Warning: Word count mismatch. Transcript: {len(words)}, Timing Data: {len(timing_words)}\")\n",
    "            print(f\"Processed transcript text: {text}\")\n",
    "            print(f\"words: \\n {words}\")\n",
    "            print(f\"Number of words: {len(words)}\")\n",
    "            print(f\"Number of entry words data: {len(timing_words)}\")\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if i >= len(timing_words):\n",
    "                print(f\"Warning: Index {i} is out of range for entry['words']\")\n",
    "                # If the timing data is shorter, skip to the next word\n",
    "                continue\n",
    "\n",
    "            word_start_time = timing_words[i]['time_s']\n",
    "            word_end_time = timing_words[i]['time_e']\n",
    "            \n",
    "            # Find the mp3 file to append the word to\n",
    "            found = False\n",
    "            for mp3 in mp3_files:\n",
    "                if (mp3['start_time'] - FLOAT_TOLERANCE <= word_start_time <= mp3['end_time'] + FLOAT_TOLERANCE):\n",
    "                    mp3['words'].append({\n",
    "                        \"word\": word,\n",
    "                        \"start_time\": word_start_time,\n",
    "                        \"end_time\": word_end_time,\n",
    "                        \"speaker\": speaker\n",
    "                    })\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                print(f\"Warning: No MP3 file found for word starting at {word_start_time}\")\n",
    "\n",
    "    return mp3_files\n",
    "\n",
    "def transform_data(mp3_files):\n",
    "    transformed = {}\n",
    "\n",
    "    for mp3 in mp3_files:\n",
    "        mp3_filename = mp3['filename']\n",
    "        mp3_start_time = mp3['start_time']\n",
    "        mp3_end_time = mp3['end_time']\n",
    "\n",
    "        # Initialize the structure for this MP3 file\n",
    "        transformed[mp3_filename] = {\n",
    "            \"Speaker\": {},\n",
    "            \"start\": mp3_start_time,\n",
    "            \"end\": mp3_end_time\n",
    "        }\n",
    "\n",
    "        for word in mp3['words']:\n",
    "            speaker = word['speaker']\n",
    "\n",
    "            if speaker not in transformed[mp3_filename][\"Speaker\"]:\n",
    "                transformed[mp3_filename][\"Speaker\"][speaker] = []\n",
    "\n",
    "            transformed[mp3_filename][\"Speaker\"][speaker].append({\n",
    "                \"word\": word['word'],\n",
    "                \"start\": word['start_time'],\n",
    "                \"end\": word['end_time']\n",
    "            })\n",
    "\n",
    "    return transformed\n",
    "\n",
    "def main():\n",
    "    # Load MP3 files data\n",
    "    mp3_files_data = load_mp3_files(mp3_files_path)\n",
    "    \n",
    "    # Prepare the output dictionary\n",
    "    consolidated_data = {}\n",
    "    \n",
    "    # Process each MP_xx.json file\n",
    "    for base_name, mp3_files in mp3_files_data.items():\n",
    "        mp3_files = sorted(mp3_files, key=lambda x: x[\"start_time\"])  # Ensure sorting by start_time\n",
    "        transcript_file_path = os.path.join(transcript_dir_path, f\"{base_name}.json\")\n",
    "        if os.path.exists(transcript_file_path):\n",
    "            transcript_data = load_transcript(transcript_file_path)\n",
    "            synced_data = sync_words_to_mp3(mp3_files, transcript_data)\n",
    "            transformed_data = transform_data(synced_data)\n",
    "            consolidated_data[base_name] = transformed_data\n",
    "        else:\n",
    "            print(f\"Transcript file for {base_name} not found.\")\n",
    "    \n",
    "    # Save the consolidated data into a JSON file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(consolidated_data, outfile, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print('Consolidated transcript data saved successfully!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8e200-7a05-4a27-9e0e-701e2a84c2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f07a1-4a45-4d26-9f16-dbd9ec1581b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56037803-d74e-4c28-909d-a32d2dda26aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:46:06.826557Z",
     "iopub.status.busy": "2024-08-05T17:46:06.826557Z",
     "iopub.status.idle": "2024-08-05T17:46:06.832282Z",
     "shell.execute_reply": "2024-08-05T17:46:06.832282Z",
     "shell.execute_reply.started": "2024-08-05T17:46:06.826557Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the base directory paths\n",
    "transcript_dir_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\MP.json\"  # Directory containing MP_00.json to MP_28.json\n",
    "mp3_files_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\all_mp3_files.json\"\n",
    "output_file_path = r\"D:\\Mici_Princ\\Mici_Princ_html\\consolidated_transcript_0.json\"\n",
    "\n",
    "# Define tolerance for floating-point comparisons\n",
    "FLOAT_TOLERANCE = 0.01  # Adjust this tolerance as needed\n",
    "\n",
    "def load_mp3_files(mp3_files_path):\n",
    "    with open(mp3_files_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_transcript(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Record positions of newlines\n",
    "    newline_positions = [m.start() for m in re.finditer(r'\\n', text)]\n",
    "\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Continue with existing preprocessing steps\n",
    "    text = re.sub(r'\\•\\s+', '•_', text)  # Combine \"• \" with following word\n",
    "    text = re.sub(r'\\-\\s+', '-_', text)  # Combine \"- \" with following word\n",
    "    text = re.sub(r'(\\S) – (\\S)', r'\\1– \\2', text)  # Handle long hyphens\n",
    "    text = re.sub(r'(\\S)-(\\S)', r'\\1- \\2', text)  # Split hyphenated words\n",
    "    text = re.sub(r'(\\S)\\s*\\.\\.\\.', r'\\1...', text)  # Append ellipses\n",
    "    text = re.sub(r'„\\s+(\\w)', r'„\\1', text)\n",
    "\n",
    "    return text, newline_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ecb69ed-6f25-4c94-916d-18372e57b627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:46:07.088914Z",
     "iopub.status.busy": "2024-08-05T17:46:07.088914Z",
     "iopub.status.idle": "2024-08-05T17:46:07.095412Z",
     "shell.execute_reply": "2024-08-05T17:46:07.094935Z",
     "shell.execute_reply.started": "2024-08-05T17:46:07.088914Z"
    }
   },
   "outputs": [],
   "source": [
    "def sync_words_to_mp3(mp3_files, transcript):\n",
    "    for mp3 in mp3_files:\n",
    "        mp3['words'] = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        speaker = entry['speaker']\n",
    "        text, newline_positions = preprocess_text(entry['text'])\n",
    "        words = text.split(' ')\n",
    "        timing_words = entry['words']\n",
    "\n",
    "        if len(words) != len(timing_words):\n",
    "            print(f\"Warning: Word count mismatch. Transcript: {len(words)}, Timing Data: {len(timing_words)}\")\n",
    "            print(f\"Processed transcript text: {text}\")\n",
    "            print(f\"words: \\n {words}\")\n",
    "            print(f\"Number of words: {len(words)}\")\n",
    "            print(f\"Number of entry words data: {len(timing_words)}\")\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if i >= len(timing_words):\n",
    "                print(f\"Warning: Index {i} is out of range for entry['words']\")\n",
    "                continue\n",
    "\n",
    "            word_start_time = timing_words[i]['time_s']\n",
    "            word_end_time = timing_words[i]['time_e']\n",
    "            \n",
    "            found = False\n",
    "            for mp3 in mp3_files:\n",
    "                if (mp3['start_time'] - FLOAT_TOLERANCE <= word_start_time <= mp3['end_time'] + FLOAT_TOLERANCE):\n",
    "                    adjusted_start_time = round(word_start_time - mp3['start_time'], 2)\n",
    "                    adjusted_end_time = round(word_end_time - mp3['start_time'], 2)\n",
    "                    \n",
    "                    mp3['words'].append({\n",
    "                        \"word\": word,\n",
    "                        \"start_time\": adjusted_start_time,\n",
    "                        \"end_time\": adjusted_end_time,\n",
    "                        \"speaker\": speaker\n",
    "                    })\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                print(f\"Warning: No MP3 file found for word starting at {word_start_time}\")\n",
    "\n",
    "    return mp3_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17d0fb42-b4eb-4d10-b78e-c991a27516c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:47:52.386192Z",
     "iopub.status.busy": "2024-08-05T17:47:52.385195Z",
     "iopub.status.idle": "2024-08-05T17:47:52.389697Z",
     "shell.execute_reply": "2024-08-05T17:47:52.389697Z",
     "shell.execute_reply.started": "2024-08-05T17:47:52.386192Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(mp3_files):\n",
    "    transformed = {}\n",
    "\n",
    "    for mp3 in mp3_files:\n",
    "        mp3_filename = mp3['filename']\n",
    "        mp3_start_time = mp3['start_time']\n",
    "        mp3_end_time = mp3['end_time']\n",
    "\n",
    "        # Initialize the structure for this MP3 file\n",
    "        transformed[mp3_filename] = {\n",
    "            \"words\": [],\n",
    "            \"start\": 0,  # After adjustment\n",
    "            \"end\": round(mp3_end_time - mp3_start_time, 2)  # Adjusted end time\n",
    "        }\n",
    "\n",
    "        for word in mp3['words']:\n",
    "            transformed[mp3_filename][\"words\"].append({\n",
    "                \"word\": word['word'],\n",
    "                \"start\": round(word['start_time'], 2),\n",
    "                \"end\": round(word['end_time'], 2),\n",
    "                \"speaker\": word['speaker']\n",
    "            })\n",
    "\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d9b308e-103a-49f3-8f38-b3f54515ae4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:47:52.672629Z",
     "iopub.status.busy": "2024-08-05T17:47:52.672629Z",
     "iopub.status.idle": "2024-08-05T17:47:52.857810Z",
     "shell.execute_reply": "2024-08-05T17:47:52.857810Z",
     "shell.execute_reply.started": "2024-08-05T17:47:52.672629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated transcript_0 data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Load MP3 files data\n",
    "    mp3_files_data = load_mp3_files(mp3_files_path)\n",
    "    \n",
    "    # Prepare the output dictionary\n",
    "    consolidated_data = {}\n",
    "    \n",
    "    # Process each MP_xx.json file\n",
    "    for base_name, mp3_files in mp3_files_data.items():\n",
    "        mp3_files = sorted(mp3_files, key=lambda x: x[\"start_time\"])  # Ensure sorting by start_time\n",
    "        transcript_file_path = os.path.join(transcript_dir_path, f\"{base_name}.json\")\n",
    "        if os.path.exists(transcript_file_path):\n",
    "            transcript_data = load_transcript(transcript_file_path)\n",
    "            synced_data = sync_words_to_mp3(mp3_files, transcript_data)\n",
    "            transformed_data = transform_data(synced_data)\n",
    "            consolidated_data[base_name] = transformed_data\n",
    "        else:\n",
    "            print(f\"Transcript file for {base_name} not found.\")\n",
    "    \n",
    "    # Save the consolidated data into a JSON file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(consolidated_data, outfile, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print('Consolidated transcript_0 data saved successfully!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43947d2-185f-461a-8fe6-53780b3752b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b36d5-44bd-47c9-b8b0-74f142885b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be6268-a8a5-43ab-a058-6f6a80de1cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
